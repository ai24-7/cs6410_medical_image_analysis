{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"IkSuTpS8JE0Y","trusted":true},"outputs":[],"source":["import tensorflow as tf\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","import numpy as np\n","import os\n","from albumentations import RandomRotate90\n","from tensorflow.keras import mixed_precision\n","import gc"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PxhKeotFJSnD","outputId":"69fcd4ec-f0c5-4c5a-fa4d-325e12759cbf","trusted":true},"outputs":[],"source":["#from google.colab import drive\n","#drive.mount('/content/drive')\n","\n","physical_devices = tf.config.list_physical_devices('GPU')\n","if len(physical_devices) > 0:\n","    for device in physical_devices:\n","        tf.config.experimental.set_memory_growth(device, True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Vsb8f2A2JoF2","trusted":true},"outputs":[],"source":["def Read_Data(path,is_train = True):\n","  temp = []\n","  updated_path = os.path.join(path,\"data\",\"VOC2007\",\"ImageSets\",\"Segmentation\",\"train.txt\" if is_train else \"val.txt\")\n","  with open(updated_path,\"r\") as file_:\n","    Instances = file_.read().split()\n","    for img in Instances:\n","      path_img = os.path.join(path,\"data\",\"VOC2007\",\"JPEGImages\",img+\".jpg\")\n","      path_label = os.path.join(path,\"data\",\"VOC2007\",\"SegmentationClass\",img+\".png\")\n","      temp.append([path_img,path_label])\n","  return temp\n","\n","Read_Data(\"\")"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"AZV5TdBtJPuk","trusted":true},"outputs":[{"ename":"NameError","evalue":"name 'Read_Data' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 2\u001b[0m Train \u001b[38;5;241m=\u001b[39m \u001b[43mRead_Data\u001b[49m(path\u001b[38;5;241m=\u001b[39mpath,is_train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      3\u001b[0m Val \u001b[38;5;241m=\u001b[39m Read_Data(path\u001b[38;5;241m=\u001b[39mpath,is_train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n","\u001b[0;31mNameError\u001b[0m: name 'Read_Data' is not defined"]}],"source":["path = ''\n","Train = Read_Data(path=path,is_train=True)\n","Val = Read_Data(path=path,is_train=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jbn_zinBNDw1","trusted":true},"outputs":[],"source":["Train = tf.random.shuffle(Train)\n","Val = tf.random.shuffle(Val)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g38UQwZ5LnRq","outputId":"84417058-651c-4ef5-bed6-f6a486d214ec","trusted":true},"outputs":[],"source":["plt.figure(figsize=(15,15))\n","idx = 0\n","img = 0\n","mask = 0\n","print(Train)\n","for instance in Train[:5].numpy():\n","  plt.subplot(5,2,idx+1)  \n","  img = Image.open(instance[0])\n","  plt.imshow(img)\n","  plt.subplot(5,2,idx+2)  \n","  mask = Image.open(instance[1])\n","  plt.imshow(mask)\n","  idx += 2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Be5aTWCvXB68","trusted":true},"outputs":[],"source":["num_classes = 21\n","Img_Width,Img_Height = 224,224\n","Train = tf.data.Dataset.from_tensor_slices(Train)\n","Val = tf.data.Dataset.from_tensor_slices(Val)\n","mixed_precision.set_global_policy('mixed_float16')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C5gl5_9OoBZm","trusted":true},"outputs":[],"source":["def Create_Mask(Img):\n","  Seg_Labels = np.zeros((Img.shape[0],Img.shape[1],num_classes),dtype=np.float16)\n","  for class_ in range(num_classes):\n","    Seg_Labels[:,:,class_] = (Img == class_)\n","  return tf.cast(Seg_Labels,dtype=tf.float16)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gQdROrK-cnRY","trusted":true},"outputs":[],"source":["def Create_PreProcess_Mask_Img(Instance):\n"," \n","  Img = Image.open(Instance[0].numpy())\n","  Img = Img.resize((Img_Width,Img_Height),resample = Image.BILINEAR)\n","  Img = np.asarray(Img)\n","\n","  Mask = Image.open(Instance[1].numpy())\n","  Mask = Mask.resize((Img_Width,Img_Height),resample = Image.BILINEAR)\n","  Mask = np.asarray(Mask)   \n","   \n","  # Since Mask is in 'P' mode it will automatically convert to labels using Color Palette \n","\n","  Normalization = tf.keras.layers.experimental.preprocessing.Rescaling(1./255)\n","\n","  if tf.random.uniform(()) > 0.5:  # Applying data Augmentation\n","    aug = RandomRotate90(p=0.5)\n","    Augmented = aug(image = Img,mask = Mask)\n","\n","    Img = Augmented[\"image\"]\n","    Mask = Augmented[\"mask\"]\n","  \n","  return Normalization(Img),Create_Mask(Mask)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"de66lN6Qae5U","trusted":true},"outputs":[],"source":["def Preprocess(Instance):\n","  Img,Mask = tf.py_function(Create_PreProcess_Mask_Img,[Instance],[tf.float16,tf.float16])\n","  return tf.ensure_shape(Img,[None,None,3]),tf.ensure_shape(Mask,[None,None,num_classes])  \n","  #tf.ensure_shape returns the matrix if shape matches else error"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wE8Lf96pXZ5-","trusted":true},"outputs":[],"source":["def DataLoader(dataset,BATCH_SIZE = 2,BUFFER_SIZE = 2):\n","  data = dataset.map(Preprocess,num_parallel_calls = tf.data.AUTOTUNE)\n","  data = data.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat(1)\n","  data = data.prefetch(buffer_size = tf.data.AUTOTUNE)\n","  return data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"F6F2KK9-pe3M","trusted":true},"outputs":[],"source":["Train = DataLoader(Train)\n","Val = DataLoader(Val)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t6e-wk3S_MSZ","outputId":"254e6090-bce6-49ca-c12c-58c3186a68c0","trusted":true},"outputs":[],"source":["Q = []\n","for X,Y in Val.take(1):\n","  print(X.shape)\n","  Q = Y\n","  print(Y.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["Q.dtype"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t3jcrzC72jYv","trusted":true},"outputs":[],"source":["# Lets Create Our FCN Model\n","def FCN_VGG8():\n","\n","  Input = tf.keras.layers.Input(shape = [Img_Width,Img_Height,3])\n","  Conv1 = tf.keras.layers.Conv2D(64,kernel_size=3,strides = 1,padding=\"same\",activation=\"relu\")(Input)\n","  Conv2 = tf.keras.layers.Conv2D(64,kernel_size=3,strides = 1,padding=\"same\",activation=\"relu\")(Conv1)\n","  Pool1 = tf.keras.layers.MaxPool2D(pool_size=2,strides=2)(Conv2)\n","\n","  Conv3 = tf.keras.layers.Conv2D(128,kernel_size=3,strides = 1,padding=\"same\",activation=\"relu\")(Pool1)\n","  Conv4 = tf.keras.layers.Conv2D(128,kernel_size=3,strides = 1,padding=\"same\",activation=\"relu\")(Conv3)\n","  Pool2 = tf.keras.layers.MaxPool2D(pool_size=2,strides=2)(Conv4)\n","\n","  Conv5 = tf.keras.layers.Conv2D(256,kernel_size=3,strides = 1,padding=\"same\",activation=\"relu\")(Pool2)\n","  Conv6 = tf.keras.layers.Conv2D(256,kernel_size=3,strides = 1,padding=\"same\",activation=\"relu\")(Conv5)\n","  Conv7 = tf.keras.layers.Conv2D(256,kernel_size=3,strides = 1,padding=\"same\",activation=\"relu\")(Conv6)\n","  Pool3 = tf.keras.layers.MaxPool2D(pool_size=2,strides=2)(Conv7)\n","\n","  Conv8 = tf.keras.layers.Conv2D(512,kernel_size=3,strides = 1,padding=\"same\",activation=\"relu\")(Pool3)\n","  Conv9 = tf.keras.layers.Conv2D(512,kernel_size=3,strides = 1,padding=\"same\",activation=\"relu\")(Conv8)\n","  Conv10 = tf.keras.layers.Conv2D(512,kernel_size=3,strides = 1,padding=\"same\",activation=\"relu\")(Conv9)\n","  Pool4 = tf.keras.layers.MaxPool2D(pool_size=2,strides=2)(Conv10)\n","\n","  Conv11 = tf.keras.layers.Conv2D(512,kernel_size=3,strides = 1,padding=\"same\",activation=\"relu\")(Pool4)\n","  Conv12 = tf.keras.layers.Conv2D(512,kernel_size=3,strides = 1,padding=\"same\",activation=\"relu\")(Conv11)\n","  Conv13 = tf.keras.layers.Conv2D(512,kernel_size=3,strides = 1,padding=\"same\",activation=\"relu\")(Conv12)\n","  Pool5 = tf.keras.layers.MaxPool2D(pool_size=2,strides=2)(Conv13)\n","\n","  # Fully Convolutional Layer\n","\n","  FC_Layer = tf.keras.layers.Conv2D(4096,kernel_size=7,activation=\"relu\")(Pool5)\n","  FC_Drop = tf.keras.layers.Dropout(rate=0.5)(FC_Layer)\n","  FC_Layer2 = tf.keras.layers.Conv2D(4096,kernel_size=1,activation=\"relu\")(FC_Drop)\n","  FC_Drop2 = tf.keras.layers.Dropout(rate=0.5)(FC_Layer2)\n","\n","  # Classification Score Layer\n","  Score = tf.keras.layers.Conv2D(num_classes,kernel_size=1,activation=\"relu\")(FC_Drop2)\n"," \n","\n","  #Upsample Pool4\n","\n","  Upscore = tf.keras.layers.Conv2DTranspose(num_classes,kernel_size=4,strides=2,kernel_initializer=\"zeros\")(Score)\n","  \n","  Conv_Scale = tf.keras.layers.Conv2D(num_classes,kernel_size=1)(Pool4)\n","  Cropped = tf.keras.layers.Cropping2D(cropping=(5,5))(Conv_Scale)\n","\n","  Fused = tf.keras.layers.add([Cropped,Upscore])\n","  \n","  Upsampled_Pool4 = tf.keras.layers.Conv2DTranspose(num_classes,kernel_size=4,strides=2,kernel_initializer=\"zeros\")(Fused)\n","\n","  \n","  # Upsample Pool3\n","\n","  Conv_Scale2 = tf.keras.layers.Conv2D(num_classes,kernel_size=1)(Pool3)\n","  Cropped2 = tf.keras.layers.Cropping2D(cropping=(9,9))(Conv_Scale2)\n","  Fused2 = tf.keras.layers.add([Cropped2,Upsampled_Pool4])\n","\n","  Upsampled_Pool3 = tf.keras.layers.Conv2DTranspose(num_classes,kernel_size=128,strides=16,kernel_initializer=\"zeros\")(Fused2)\n","\n","  # Score per Pixel\n","\n","  Score = tf.keras.layers.Cropping2D(cropping=(24,24))(Upsampled_Pool3)\n","  Score = tf.keras.layers.Softmax(dtype = \"float32\")(Score)\n","\n","  return tf.keras.Model(inputs = Input,outputs = Score)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EMCUc7pZKbRQ","trusted":true},"outputs":[],"source":["model = FCN_VGG8()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UvabXhe7cD7K","outputId":"6a433d51-5066-4fac-9498-c731bc05018d","trusted":true},"outputs":[],"source":["tf.keras.utils.plot_model(model,show_shapes=True,show_dtype=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qK2q1kxKeBsX","outputId":"340bc669-762b-4a66-df99-d4fb6c28d632","trusted":true},"outputs":[],"source":["model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G1YjHEFecZ_X","outputId":"2814dcec-9ab9-41b0-cd25-073f3796e60d","trusted":true},"outputs":[],"source":["VGG16 = tf.keras.applications.vgg16.VGG16(weights='imagenet')\n","VGG16.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"51CNiRGGeL-H","outputId":"37e7c0fd-9fb6-4bff-8c6f-a6d714643f66","trusted":true},"outputs":[],"source":["model.layers[:19]"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["for i in model.layers:\n","    print(i.dtype_policy)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DGNawvE-fSop","trusted":true},"outputs":[],"source":["for i in range(19):\n","  model.layers[i].set_weights(VGG16.layers[i].get_weights())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JZqissfnj3hb","trusted":true},"outputs":[],"source":["root_dir = os.path.join(os.curdir,\"my_logs\")\n","\n","def get_path():\n","    import time\n","    id_ = time.strftime(\"run_%Y_%m_%D_%H_%M_%S\")\n","    return os.path.join(root_dir,id_)\n","\n","board_log_path = get_path()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oUcYilpBgooM","trusted":true},"outputs":[],"source":["for layers in model.layers[:19]:\n","  layers.trainable = False"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UAI1SkbnjdKv","trusted":true},"outputs":[],"source":["EarlyStop = tf.keras.callbacks.EarlyStopping(patience = 10,restore_best_weights=True)\n","checkpoint_path = os.path.join(os.curdir,\"checkpoint\")\n","Checkpoint = tf.keras.callbacks.ModelCheckpoint(checkpoint_path,save_best_only=True)\n","Tensorboard = tf.keras.callbacks.TensorBoard(board_log_path)\n","\n","MeanIou = tf.keras.metrics.MeanIoU(num_classes=21)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["gc.collect()\n","gc.enable()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["tf.keras.backend.clear_session()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fnX4j2cGhU0y","trusted":true},"outputs":[],"source":["model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=1e-4,momentum=0.9),loss=tf.keras.losses.categorical_crossentropy,metrics=[MeanIou])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0b03QMUFmJPE","outputId":"8e9caad2-6d75-4828-fb8d-97f6a5b42176","trusted":true},"outputs":[],"source":["Epochs = 100\n","Batchsize = 2\n","\n","history = model.fit(Train,validation_data=Val,batch_size=Batchsize,epochs=Epochs,callbacks=[EarlyStop,Checkpoint,Tensorboard])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mj2urzeAoZ6O","trusted":true},"outputs":[],"source":["model.load_weights(checkpoint_path)"]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5IoOCASNrDoG","trusted":true},"outputs":[],"source":["pd.DataFrame(history.history).plot(figsize = (10,8))\n","plt.grid('True')\n","plt.savefig(\"Learning_Curve_Model1.png\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0LBi-FWTr8Jw","trusted":true},"outputs":[],"source":["for layer in model.layers:\n","    layer.trainable = True"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eXn5K3dDr-we","trusted":true},"outputs":[],"source":["Epochs = 300\n","Batchsize = 2\n","\n","history = model.fit(Train,validation_data=Val,batch_size=Batchsize,epochs=Epochs,callbacks=[EarlyStop,Checkpoint,Tensorboard])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X9UquvBpmBQA","trusted":true},"outputs":[],"source":["model.load_weights(checkpoint_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["pd.DataFrame(history.history).plot(figsize = (10,8))\n","plt.grid('True')\n","plt.savefig(\"Learning_Curve_Model1.png\")\n","plt.show()"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.18"}},"nbformat":4,"nbformat_minor":4}

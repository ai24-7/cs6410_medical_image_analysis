{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.nn.functional import relu\n",
    "from torchvision import transforms,models\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "#train and test data directory\n",
    "train_dir = \"data/images/train/\"\n",
    "trainval_dir = \"data/images/trainval/\"\n",
    "val_dir = \"data/images/val/\"\n",
    "\n",
    "\n",
    "#load the train data\n",
    "dataset_train = ImageFolder(train_dir,transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),transforms.ToTensor()\n",
    "]))\n",
    "\n",
    "#load the test data\n",
    "dataset_trainval = ImageFolder(trainval_dir,transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),transforms.ToTensor()\n",
    "]))\n",
    "\n",
    "#load the validation data\n",
    "dataset_val = ImageFolder(val_dir,transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),transforms.ToTensor()\n",
    "]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_class):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Encoder\n",
    "        # In the encoder, convolutional layers with the Conv2d function are used to extract features from the input image. \n",
    "        # Each block in the encoder consists of two convolutional layers followed by a max-pooling layer, with the exception of the last block which does not include a max-pooling layer.\n",
    "        # -------\n",
    "        # input: 572x572x3\n",
    "        self.e11 = nn.Conv2d(3, 64, kernel_size=3, padding=1) # output: 570x570x64\n",
    "        self.e12 = nn.Conv2d(64, 64, kernel_size=3, padding=1) # output: 568x568x64\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2) # output: 284x284x64\n",
    "\n",
    "        # input: 284x284x64\n",
    "        self.e21 = nn.Conv2d(64, 128, kernel_size=3, padding=1) # output: 282x282x128\n",
    "        self.e22 = nn.Conv2d(128, 128, kernel_size=3, padding=1) # output: 280x280x128\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2) # output: 140x140x128\n",
    "\n",
    "        # input: 140x140x128\n",
    "        self.e31 = nn.Conv2d(128, 256, kernel_size=3, padding=1) # output: 138x138x256\n",
    "        self.e32 = nn.Conv2d(256, 256, kernel_size=3, padding=1) # output: 136x136x256\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2) # output: 68x68x256\n",
    "\n",
    "        # input: 68x68x256\n",
    "        self.e41 = nn.Conv2d(256, 512, kernel_size=3, padding=1) # output: 66x66x512\n",
    "        self.e42 = nn.Conv2d(512, 512, kernel_size=3, padding=1) # output: 64x64x512\n",
    "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2) # output: 32x32x512\n",
    "\n",
    "        # input: 32x32x512\n",
    "        self.e51 = nn.Conv2d(512, 1024, kernel_size=3, padding=1) # output: 30x30x1024\n",
    "        self.e52 = nn.Conv2d(1024, 1024, kernel_size=3, padding=1) # output: 28x28x1024\n",
    "\n",
    "\n",
    "        # Decoder\n",
    "        self.upconv1 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)\n",
    "        self.d11 = nn.Conv2d(1024, 512, kernel_size=3, padding=1)\n",
    "        self.d12 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "\n",
    "        self.upconv2 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
    "        self.d21 = nn.Conv2d(512, 256, kernel_size=3, padding=1)\n",
    "        self.d22 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
    "\n",
    "        self.upconv3 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
    "        self.d31 = nn.Conv2d(256, 128, kernel_size=3, padding=1)\n",
    "        self.d32 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "\n",
    "        self.upconv4 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "        self.d41 = nn.Conv2d(128, 64, kernel_size=3, padding=1)\n",
    "        self.d42 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
    "\n",
    "        # Output layer\n",
    "        self.outconv = nn.Conv2d(64, n_class, kernel_size=1)\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        xe11 = relu(self.e11(x))\n",
    "        xe12 = relu(self.e12(xe11))\n",
    "        xp1 = self.pool1(xe12)\n",
    "\n",
    "        xe21 = relu(self.e21(xp1))\n",
    "        xe22 = relu(self.e22(xe21))\n",
    "        xp2 = self.pool2(xe22)\n",
    "\n",
    "        xe31 = relu(self.e31(xp2))\n",
    "        xe32 = relu(self.e32(xe31))\n",
    "        xp3 = self.pool3(xe32)\n",
    "\n",
    "        xe41 = relu(self.e41(xp3))\n",
    "        xe42 = relu(self.e42(xe41))\n",
    "        xp4 = self.pool4(xe42)\n",
    "\n",
    "        xe51 = relu(self.e51(xp4))\n",
    "        xe52 = relu(self.e52(xe51))\n",
    "        \n",
    "        # Decoder\n",
    "        xu1 = self.upconv1(xe52)\n",
    "        xu11 = torch.cat([xu1, xe42], dim=1)\n",
    "        xd11 = relu(self.d11(xu11))\n",
    "        xd12 = relu(self.d12(xd11))\n",
    "\n",
    "        xu2 = self.upconv2(xd12)\n",
    "        xu22 = torch.cat([xu2, xe32], dim=1)\n",
    "        xd21 = relu(self.d21(xu22))\n",
    "        xd22 = relu(self.d22(xd21))\n",
    "\n",
    "        xu3 = self.upconv3(xd22)\n",
    "        xu33 = torch.cat([xu3, xe22], dim=1)\n",
    "        xd31 = relu(self.d31(xu33))\n",
    "        xd32 = relu(self.d32(xd31))\n",
    "\n",
    "        xu4 = self.upconv4(xd32)\n",
    "        xu44 = torch.cat([xu4, xe12], dim=1)\n",
    "        xd41 = relu(self.d41(xu44))\n",
    "        xd42 = relu(self.d42(xd41))\n",
    "\n",
    "        # Output layer\n",
    "        out = self.outconv(xd42)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import test_u_net\n",
    "\n",
    "def run(Unet):\n",
    "    num_class = 6\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    model = UNet(num_class).to(device)\n",
    "\n",
    "    optimizer_ft = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-5)\n",
    "\n",
    "    exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=30, gamma=0.1)\n",
    "    model = train_model(model, optimizer_ft, exp_lr_scheduler, num_epochs=300)\n",
    "\n",
    "    model.eval()  # Set model to the evaluation mode\n",
    "\n",
    "    trans = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # imagenet\n",
    "    ])\n",
    "    # # Create another simulation dataset for test\n",
    "    test_dataset = SimDataset(3, transform = trans)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=3, shuffle=False, num_workers=0)\n",
    "\n",
    "    # Get the first batch\n",
    "    inputs, labels = next(iter(test_loader))\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    # Predict\n",
    "    pred = model(inputs)\n",
    "    # The loss functions include the sigmoid function.\n",
    "    pred = F.sigmoid(pred)\n",
    "    pred = pred.data.cpu().numpy()\n",
    "    print(pred.shape)\n",
    "\n",
    "    # Change channel-order and make 3 channels for matplot\n",
    "    input_images_rgb = [reverse_transform(x) for x in inputs.cpu()]\n",
    "\n",
    "    # Map each channel (i.e. class) to each color\n",
    "    target_masks_rgb = [masks_to_colorimg(x) for x in labels.cpu().numpy()]\n",
    "    pred_rgb = [masks_to_colorimg(x) for x in pred]\n",
    "\n",
    "    plot_side_by_side([input_images_rgb, target_masks_rgb, pred_rgb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Epoch 0/299\n",
      "----------\n",
      "LR 1e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/toldo/miniconda3/envs/rai_py38_poetry_enn/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: bce: 0.673879, dice: 0.990964, loss: 0.832422\n",
      "val: bce: 0.672425, dice: 0.990580, loss: 0.831502\n",
      "saving best model\n",
      "0m 2s\n",
      "Epoch 1/299\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.671569, dice: 0.990952, loss: 0.831260\n",
      "val: bce: 0.670169, dice: 0.990567, loss: 0.830368\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 2/299\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.669363, dice: 0.990940, loss: 0.830151\n",
      "val: bce: 0.668067, dice: 0.990555, loss: 0.829311\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 3/299\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.667394, dice: 0.990929, loss: 0.829161\n",
      "val: bce: 0.666433, dice: 0.990546, loss: 0.828490\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 4/299\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.665888, dice: 0.990922, loss: 0.828405\n",
      "val: bce: 0.665013, dice: 0.990539, loss: 0.827776\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 5/299\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.664463, dice: 0.990915, loss: 0.827689\n",
      "val: bce: 0.663596, dice: 0.990532, loss: 0.827064\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 6/299\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.663040, dice: 0.990908, loss: 0.826974\n",
      "val: bce: 0.662125, dice: 0.990525, loss: 0.826325\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 7/299\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.661491, dice: 0.990900, loss: 0.826195\n",
      "val: bce: 0.660429, dice: 0.990515, loss: 0.825472\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 8/299\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.659779, dice: 0.990890, loss: 0.825335\n",
      "val: bce: 0.658746, dice: 0.990505, loss: 0.824626\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 9/299\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.658067, dice: 0.990881, loss: 0.824474\n",
      "val: bce: 0.656941, dice: 0.990495, loss: 0.823718\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 10/299\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.656190, dice: 0.990871, loss: 0.823531\n",
      "val: bce: 0.654964, dice: 0.990485, loss: 0.822724\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 11/299\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.654153, dice: 0.990860, loss: 0.822507\n",
      "val: bce: 0.652848, dice: 0.990474, loss: 0.821661\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 12/299\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.652046, dice: 0.990850, loss: 0.821448\n",
      "val: bce: 0.650725, dice: 0.990464, loss: 0.820594\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 13/299\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.649832, dice: 0.990840, loss: 0.820336\n",
      "val: bce: 0.648370, dice: 0.990453, loss: 0.819411\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 14/299\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.647396, dice: 0.990829, loss: 0.819112\n",
      "val: bce: 0.645795, dice: 0.990442, loss: 0.818118\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 15/299\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.644724, dice: 0.990818, loss: 0.817771\n",
      "val: bce: 0.642975, dice: 0.990430, loss: 0.816703\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 16/299\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.641814, dice: 0.990806, loss: 0.816310\n",
      "val: bce: 0.639898, dice: 0.990418, loss: 0.815158\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 17/299\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.638578, dice: 0.990795, loss: 0.814686\n",
      "val: bce: 0.636373, dice: 0.990406, loss: 0.813390\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 18/299\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.634852, dice: 0.990782, loss: 0.812817\n",
      "val: bce: 0.632308, dice: 0.990393, loss: 0.811350\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 19/299\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.630551, dice: 0.990769, loss: 0.810660\n",
      "val: bce: 0.627566, dice: 0.990379, loss: 0.808973\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 20/299\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.625481, dice: 0.990756, loss: 0.808118\n",
      "val: bce: 0.621914, dice: 0.990365, loss: 0.806140\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 21/299\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.619435, dice: 0.990742, loss: 0.805089\n",
      "val: bce: 0.615165, dice: 0.990353, loss: 0.802759\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 22/299\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.612148, dice: 0.990731, loss: 0.801440\n",
      "val: bce: 0.606786, dice: 0.990345, loss: 0.798566\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 23/299\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.602865, dice: 0.990725, loss: 0.796795\n",
      "val: bce: 0.595787, dice: 0.990344, loss: 0.793065\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 24/299\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.590411, dice: 0.990727, loss: 0.790569\n",
      "val: bce: 0.580391, dice: 0.990354, loss: 0.785373\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 25/299\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.572534, dice: 0.990743, loss: 0.781638\n",
      "val: bce: 0.557508, dice: 0.990385, loss: 0.773947\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 26/299\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.545206, dice: 0.990784, loss: 0.767995\n",
      "val: bce: 0.521056, dice: 0.990461, loss: 0.755758\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 27/299\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.500508, dice: 0.990887, loss: 0.745698\n",
      "val: bce: 0.459181, dice: 0.990648, loss: 0.724914\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 28/299\n",
      "----------\n",
      "LR 1e-05\n",
      "train: bce: 0.422591, dice: 0.991147, loss: 0.706869\n",
      "val: bce: 0.348405, dice: 0.991170, loss: 0.669787\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 29/299\n",
      "----------\n",
      "LR 1.0000000000000002e-06\n",
      "train: bce: 0.342702, dice: 0.991531, loss: 0.667117\n",
      "val: bce: 0.333199, dice: 0.991268, loss: 0.662234\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 30/299\n",
      "----------\n",
      "LR 1.0000000000000002e-06\n",
      "train: bce: 0.326985, dice: 0.991630, loss: 0.659308\n",
      "val: bce: 0.316735, dice: 0.991384, loss: 0.654060\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 31/299\n",
      "----------\n",
      "LR 1.0000000000000002e-06\n",
      "train: bce: 0.310185, dice: 0.991744, loss: 0.650965\n",
      "val: bce: 0.299510, dice: 0.991519, loss: 0.645514\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 32/299\n",
      "----------\n",
      "LR 1.0000000000000002e-06\n",
      "train: bce: 0.292731, dice: 0.991878, loss: 0.642304\n",
      "val: bce: 0.281752, dice: 0.991671, loss: 0.636712\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 33/299\n",
      "----------\n",
      "LR 1.0000000000000002e-06\n",
      "train: bce: 0.274818, dice: 0.992027, loss: 0.633422\n",
      "val: bce: 0.263710, dice: 0.991842, loss: 0.627776\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 34/299\n",
      "----------\n",
      "LR 1.0000000000000002e-06\n",
      "train: bce: 0.256725, dice: 0.992195, loss: 0.624460\n",
      "val: bce: 0.245564, dice: 0.992035, loss: 0.618799\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 35/299\n",
      "----------\n",
      "LR 1.0000000000000002e-06\n",
      "train: bce: 0.238540, dice: 0.992386, loss: 0.615463\n",
      "val: bce: 0.227466, dice: 0.992250, loss: 0.609858\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 36/299\n",
      "----------\n",
      "LR 1.0000000000000002e-06\n",
      "train: bce: 0.220494, dice: 0.992597, loss: 0.606545\n",
      "val: bce: 0.209564, dice: 0.992492, loss: 0.601028\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 37/299\n",
      "----------\n",
      "LR 1.0000000000000002e-06\n",
      "train: bce: 0.202708, dice: 0.992832, loss: 0.597770\n",
      "val: bce: 0.192184, dice: 0.992759, loss: 0.592472\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 38/299\n",
      "----------\n",
      "LR 1.0000000000000002e-06\n",
      "train: bce: 0.185520, dice: 0.993095, loss: 0.589307\n",
      "val: bce: 0.175478, dice: 0.993053, loss: 0.584265\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 39/299\n",
      "----------\n",
      "LR 1.0000000000000002e-06\n",
      "train: bce: 0.169089, dice: 0.993379, loss: 0.581234\n",
      "val: bce: 0.159607, dice: 0.993370, loss: 0.576488\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 40/299\n",
      "----------\n",
      "LR 1.0000000000000002e-06\n",
      "train: bce: 0.153544, dice: 0.993693, loss: 0.573618\n",
      "val: bce: 0.144779, dice: 0.993711, loss: 0.569245\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 41/299\n",
      "----------\n",
      "LR 1.0000000000000002e-06\n",
      "train: bce: 0.139141, dice: 0.994023, loss: 0.566582\n",
      "val: bce: 0.131195, dice: 0.994070, loss: 0.562633\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 42/299\n",
      "----------\n",
      "LR 1.0000000000000002e-06\n",
      "train: bce: 0.125962, dice: 0.994366, loss: 0.560164\n",
      "val: bce: 0.118925, dice: 0.994441, loss: 0.556683\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 43/299\n",
      "----------\n",
      "LR 1.0000000000000002e-06\n",
      "train: bce: 0.114189, dice: 0.994724, loss: 0.554457\n",
      "val: bce: 0.108122, dice: 0.994816, loss: 0.551469\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 44/299\n",
      "----------\n",
      "LR 1.0000000000000002e-06\n",
      "train: bce: 0.103843, dice: 0.995080, loss: 0.549462\n",
      "val: bce: 0.098708, dice: 0.995186, loss: 0.546947\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 45/299\n",
      "----------\n",
      "LR 1.0000000000000002e-06\n",
      "train: bce: 0.094882, dice: 0.995432, loss: 0.545157\n",
      "val: bce: 0.090621, dice: 0.995545, loss: 0.543083\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 46/299\n",
      "----------\n",
      "LR 1.0000000000000002e-06\n",
      "train: bce: 0.087213, dice: 0.995768, loss: 0.541490\n",
      "val: bce: 0.083816, dice: 0.995884, loss: 0.539850\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 47/299\n",
      "----------\n",
      "LR 1.0000000000000002e-06\n",
      "train: bce: 0.080792, dice: 0.996088, loss: 0.538440\n",
      "val: bce: 0.078162, dice: 0.996198, loss: 0.537180\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 48/299\n",
      "----------\n",
      "LR 1.0000000000000002e-06\n",
      "train: bce: 0.075463, dice: 0.996375, loss: 0.535919\n",
      "val: bce: 0.073533, dice: 0.996481, loss: 0.535007\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 49/299\n",
      "----------\n",
      "LR 1.0000000000000002e-06\n",
      "train: bce: 0.071114, dice: 0.996639, loss: 0.533876\n",
      "val: bce: 0.069752, dice: 0.996734, loss: 0.533243\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 50/299\n",
      "----------\n",
      "LR 1.0000000000000002e-06\n",
      "train: bce: 0.067566, dice: 0.996874, loss: 0.532220\n",
      "val: bce: 0.066716, dice: 0.996956, loss: 0.531836\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 51/299\n",
      "----------\n",
      "LR 1.0000000000000002e-06\n",
      "train: bce: 0.064712, dice: 0.997078, loss: 0.530895\n",
      "val: bce: 0.064276, dice: 0.997148, loss: 0.530712\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 52/299\n",
      "----------\n",
      "LR 1.0000000000000002e-06\n",
      "train: bce: 0.062413, dice: 0.997252, loss: 0.529833\n",
      "val: bce: 0.062350, dice: 0.997311, loss: 0.529831\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 53/299\n",
      "----------\n",
      "LR 1.0000000000000002e-06\n",
      "train: bce: 0.060600, dice: 0.997401, loss: 0.529001\n",
      "val: bce: 0.060823, dice: 0.997450, loss: 0.529136\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 54/299\n",
      "----------\n",
      "LR 1.0000000000000002e-06\n",
      "train: bce: 0.059151, dice: 0.997525, loss: 0.528338\n",
      "val: bce: 0.059623, dice: 0.997565, loss: 0.528594\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 55/299\n",
      "----------\n",
      "LR 1.0000000000000002e-06\n",
      "train: bce: 0.058016, dice: 0.997632, loss: 0.527824\n",
      "val: bce: 0.058677, dice: 0.997662, loss: 0.528169\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 56/299\n",
      "----------\n",
      "LR 1.0000000000000002e-06\n",
      "train: bce: 0.057101, dice: 0.997718, loss: 0.527409\n",
      "val: bce: 0.057921, dice: 0.997743, loss: 0.527832\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 57/299\n",
      "----------\n",
      "LR 1.0000000000000002e-06\n",
      "train: bce: 0.056378, dice: 0.997791, loss: 0.527085\n",
      "val: bce: 0.057333, dice: 0.997809, loss: 0.527571\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 58/299\n",
      "----------\n",
      "LR 1.0000000000000002e-06\n",
      "train: bce: 0.055806, dice: 0.997849, loss: 0.526828\n",
      "val: bce: 0.056864, dice: 0.997863, loss: 0.527363\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 59/299\n",
      "----------\n",
      "LR 1.0000000000000002e-07\n",
      "train: bce: 0.055491, dice: 0.997883, loss: 0.526687\n",
      "val: bce: 0.056823, dice: 0.997868, loss: 0.527345\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 60/299\n",
      "----------\n",
      "LR 1.0000000000000002e-07\n",
      "train: bce: 0.055448, dice: 0.997887, loss: 0.526668\n",
      "val: bce: 0.056789, dice: 0.997872, loss: 0.527330\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 61/299\n",
      "----------\n",
      "LR 1.0000000000000002e-07\n",
      "train: bce: 0.055413, dice: 0.997891, loss: 0.526652\n",
      "val: bce: 0.056758, dice: 0.997875, loss: 0.527317\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 62/299\n",
      "----------\n",
      "LR 1.0000000000000002e-07\n",
      "train: bce: 0.055377, dice: 0.997895, loss: 0.526636\n",
      "val: bce: 0.056721, dice: 0.997879, loss: 0.527300\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 63/299\n",
      "----------\n",
      "LR 1.0000000000000002e-07\n",
      "train: bce: 0.055342, dice: 0.997898, loss: 0.526620\n",
      "val: bce: 0.056691, dice: 0.997882, loss: 0.527287\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 64/299\n",
      "----------\n",
      "LR 1.0000000000000002e-07\n",
      "train: bce: 0.055311, dice: 0.997901, loss: 0.526606\n",
      "val: bce: 0.056664, dice: 0.997886, loss: 0.527275\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 65/299\n",
      "----------\n",
      "LR 1.0000000000000002e-07\n",
      "train: bce: 0.055279, dice: 0.997904, loss: 0.526592\n",
      "val: bce: 0.056632, dice: 0.997889, loss: 0.527260\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 66/299\n",
      "----------\n",
      "LR 1.0000000000000002e-07\n",
      "train: bce: 0.055248, dice: 0.997907, loss: 0.526578\n",
      "val: bce: 0.056605, dice: 0.997892, loss: 0.527249\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 67/299\n",
      "----------\n",
      "LR 1.0000000000000002e-07\n",
      "train: bce: 0.055219, dice: 0.997910, loss: 0.526565\n",
      "val: bce: 0.056577, dice: 0.997895, loss: 0.527236\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 68/299\n",
      "----------\n",
      "LR 1.0000000000000002e-07\n",
      "train: bce: 0.055190, dice: 0.997913, loss: 0.526551\n",
      "val: bce: 0.056550, dice: 0.997898, loss: 0.527224\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 69/299\n",
      "----------\n",
      "LR 1.0000000000000002e-07\n",
      "train: bce: 0.055161, dice: 0.997916, loss: 0.526539\n",
      "val: bce: 0.056523, dice: 0.997901, loss: 0.527212\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 70/299\n",
      "----------\n",
      "LR 1.0000000000000002e-07\n",
      "train: bce: 0.055133, dice: 0.997919, loss: 0.526526\n",
      "val: bce: 0.056495, dice: 0.997904, loss: 0.527199\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 71/299\n",
      "----------\n",
      "LR 1.0000000000000002e-07\n",
      "train: bce: 0.055102, dice: 0.997921, loss: 0.526512\n",
      "val: bce: 0.056468, dice: 0.997907, loss: 0.527187\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 72/299\n",
      "----------\n",
      "LR 1.0000000000000002e-07\n",
      "train: bce: 0.055074, dice: 0.997924, loss: 0.526499\n",
      "val: bce: 0.056443, dice: 0.997909, loss: 0.527176\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 73/299\n",
      "----------\n",
      "LR 1.0000000000000002e-07\n",
      "train: bce: 0.055049, dice: 0.997927, loss: 0.526488\n",
      "val: bce: 0.056420, dice: 0.997912, loss: 0.527166\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 74/299\n",
      "----------\n",
      "LR 1.0000000000000002e-07\n",
      "train: bce: 0.055022, dice: 0.997930, loss: 0.526476\n",
      "val: bce: 0.056393, dice: 0.997915, loss: 0.527154\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 75/299\n",
      "----------\n",
      "LR 1.0000000000000002e-07\n",
      "train: bce: 0.054994, dice: 0.997932, loss: 0.526463\n",
      "val: bce: 0.056368, dice: 0.997918, loss: 0.527143\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 76/299\n",
      "----------\n",
      "LR 1.0000000000000002e-07\n",
      "train: bce: 0.054968, dice: 0.997935, loss: 0.526452\n",
      "val: bce: 0.056342, dice: 0.997921, loss: 0.527131\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 77/299\n",
      "----------\n",
      "LR 1.0000000000000002e-07\n",
      "train: bce: 0.054940, dice: 0.997938, loss: 0.526439\n",
      "val: bce: 0.056318, dice: 0.997923, loss: 0.527120\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 78/299\n",
      "----------\n",
      "LR 1.0000000000000002e-07\n",
      "train: bce: 0.054915, dice: 0.997940, loss: 0.526428\n",
      "val: bce: 0.056295, dice: 0.997926, loss: 0.527110\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 79/299\n",
      "----------\n",
      "LR 1.0000000000000002e-07\n",
      "train: bce: 0.054889, dice: 0.997943, loss: 0.526416\n",
      "val: bce: 0.056268, dice: 0.997929, loss: 0.527098\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 80/299\n",
      "----------\n",
      "LR 1.0000000000000002e-07\n",
      "train: bce: 0.054862, dice: 0.997945, loss: 0.526404\n",
      "val: bce: 0.056245, dice: 0.997931, loss: 0.527088\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 81/299\n",
      "----------\n",
      "LR 1.0000000000000002e-07\n",
      "train: bce: 0.054838, dice: 0.997948, loss: 0.526393\n",
      "val: bce: 0.056222, dice: 0.997934, loss: 0.527078\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 82/299\n",
      "----------\n",
      "LR 1.0000000000000002e-07\n",
      "train: bce: 0.054813, dice: 0.997950, loss: 0.526381\n",
      "val: bce: 0.056199, dice: 0.997936, loss: 0.527068\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 83/299\n",
      "----------\n",
      "LR 1.0000000000000002e-07\n",
      "train: bce: 0.054788, dice: 0.997953, loss: 0.526371\n",
      "val: bce: 0.056176, dice: 0.997939, loss: 0.527058\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 84/299\n",
      "----------\n",
      "LR 1.0000000000000002e-07\n",
      "train: bce: 0.054764, dice: 0.997955, loss: 0.526360\n",
      "val: bce: 0.056153, dice: 0.997941, loss: 0.527047\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 85/299\n",
      "----------\n",
      "LR 1.0000000000000002e-07\n",
      "train: bce: 0.054740, dice: 0.997957, loss: 0.526349\n",
      "val: bce: 0.056133, dice: 0.997944, loss: 0.527038\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 86/299\n",
      "----------\n",
      "LR 1.0000000000000002e-07\n",
      "train: bce: 0.054718, dice: 0.997960, loss: 0.526339\n",
      "val: bce: 0.056112, dice: 0.997946, loss: 0.527029\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 87/299\n",
      "----------\n",
      "LR 1.0000000000000002e-07\n",
      "train: bce: 0.054695, dice: 0.997962, loss: 0.526329\n",
      "val: bce: 0.056091, dice: 0.997949, loss: 0.527020\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 88/299\n",
      "----------\n",
      "LR 1.0000000000000002e-07\n",
      "train: bce: 0.054673, dice: 0.997965, loss: 0.526319\n",
      "val: bce: 0.056069, dice: 0.997951, loss: 0.527010\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 89/299\n",
      "----------\n",
      "LR 1.0000000000000004e-08\n",
      "train: bce: 0.054657, dice: 0.997966, loss: 0.526312\n",
      "val: bce: 0.056067, dice: 0.997951, loss: 0.527009\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 90/299\n",
      "----------\n",
      "LR 1.0000000000000004e-08\n",
      "train: bce: 0.054655, dice: 0.997966, loss: 0.526311\n",
      "val: bce: 0.056066, dice: 0.997952, loss: 0.527009\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 91/299\n",
      "----------\n",
      "LR 1.0000000000000004e-08\n",
      "train: bce: 0.054654, dice: 0.997967, loss: 0.526310\n",
      "val: bce: 0.056064, dice: 0.997952, loss: 0.527008\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 92/299\n",
      "----------\n",
      "LR 1.0000000000000004e-08\n",
      "train: bce: 0.054652, dice: 0.997967, loss: 0.526309\n",
      "val: bce: 0.056062, dice: 0.997952, loss: 0.527007\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 93/299\n",
      "----------\n",
      "LR 1.0000000000000004e-08\n",
      "train: bce: 0.054649, dice: 0.997967, loss: 0.526308\n",
      "val: bce: 0.056059, dice: 0.997953, loss: 0.527006\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 94/299\n",
      "----------\n",
      "LR 1.0000000000000004e-08\n",
      "train: bce: 0.054647, dice: 0.997967, loss: 0.526307\n",
      "val: bce: 0.056058, dice: 0.997953, loss: 0.527005\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 95/299\n",
      "----------\n",
      "LR 1.0000000000000004e-08\n",
      "train: bce: 0.054643, dice: 0.997968, loss: 0.526305\n",
      "val: bce: 0.056052, dice: 0.997953, loss: 0.527003\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 96/299\n",
      "----------\n",
      "LR 1.0000000000000004e-08\n",
      "train: bce: 0.054639, dice: 0.997968, loss: 0.526303\n",
      "val: bce: 0.056049, dice: 0.997953, loss: 0.527001\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 97/299\n",
      "----------\n",
      "LR 1.0000000000000004e-08\n",
      "train: bce: 0.054636, dice: 0.997968, loss: 0.526302\n",
      "val: bce: 0.056047, dice: 0.997953, loss: 0.527000\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 98/299\n",
      "----------\n",
      "LR 1.0000000000000004e-08\n",
      "train: bce: 0.054634, dice: 0.997968, loss: 0.526301\n",
      "val: bce: 0.056045, dice: 0.997954, loss: 0.526999\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 99/299\n",
      "----------\n",
      "LR 1.0000000000000004e-08\n",
      "train: bce: 0.054632, dice: 0.997968, loss: 0.526300\n",
      "val: bce: 0.056043, dice: 0.997954, loss: 0.526998\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 100/299\n",
      "----------\n",
      "LR 1.0000000000000004e-08\n",
      "train: bce: 0.054630, dice: 0.997969, loss: 0.526299\n",
      "val: bce: 0.056041, dice: 0.997954, loss: 0.526998\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 101/299\n",
      "----------\n",
      "LR 1.0000000000000004e-08\n",
      "train: bce: 0.054628, dice: 0.997969, loss: 0.526298\n",
      "val: bce: 0.056039, dice: 0.997954, loss: 0.526997\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 102/299\n",
      "----------\n",
      "LR 1.0000000000000004e-08\n",
      "train: bce: 0.054626, dice: 0.997969, loss: 0.526297\n",
      "val: bce: 0.056037, dice: 0.997955, loss: 0.526996\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 103/299\n",
      "----------\n",
      "LR 1.0000000000000004e-08\n",
      "train: bce: 0.054623, dice: 0.997969, loss: 0.526296\n",
      "val: bce: 0.056035, dice: 0.997955, loss: 0.526995\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 104/299\n",
      "----------\n",
      "LR 1.0000000000000004e-08\n",
      "train: bce: 0.054621, dice: 0.997970, loss: 0.526295\n",
      "val: bce: 0.056033, dice: 0.997955, loss: 0.526994\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 105/299\n",
      "----------\n",
      "LR 1.0000000000000004e-08\n",
      "train: bce: 0.054619, dice: 0.997970, loss: 0.526294\n",
      "val: bce: 0.056030, dice: 0.997955, loss: 0.526993\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 106/299\n",
      "----------\n",
      "LR 1.0000000000000004e-08\n",
      "train: bce: 0.054615, dice: 0.997970, loss: 0.526293\n",
      "val: bce: 0.056027, dice: 0.997956, loss: 0.526991\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 107/299\n",
      "----------\n",
      "LR 1.0000000000000004e-08\n",
      "train: bce: 0.054612, dice: 0.997970, loss: 0.526291\n",
      "val: bce: 0.056025, dice: 0.997956, loss: 0.526990\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 108/299\n",
      "----------\n",
      "LR 1.0000000000000004e-08\n",
      "train: bce: 0.054610, dice: 0.997971, loss: 0.526290\n",
      "val: bce: 0.056023, dice: 0.997956, loss: 0.526989\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 109/299\n",
      "----------\n",
      "LR 1.0000000000000004e-08\n",
      "train: bce: 0.054608, dice: 0.997971, loss: 0.526289\n",
      "val: bce: 0.056021, dice: 0.997956, loss: 0.526988\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 110/299\n",
      "----------\n",
      "LR 1.0000000000000004e-08\n",
      "train: bce: 0.054606, dice: 0.997971, loss: 0.526288\n",
      "val: bce: 0.056018, dice: 0.997957, loss: 0.526987\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 111/299\n",
      "----------\n",
      "LR 1.0000000000000004e-08\n",
      "train: bce: 0.054603, dice: 0.997971, loss: 0.526287\n",
      "val: bce: 0.056016, dice: 0.997957, loss: 0.526986\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 112/299\n",
      "----------\n",
      "LR 1.0000000000000004e-08\n",
      "train: bce: 0.054601, dice: 0.997971, loss: 0.526286\n",
      "val: bce: 0.056014, dice: 0.997957, loss: 0.526986\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 113/299\n",
      "----------\n",
      "LR 1.0000000000000004e-08\n",
      "train: bce: 0.054598, dice: 0.997972, loss: 0.526285\n",
      "val: bce: 0.056012, dice: 0.997957, loss: 0.526985\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 114/299\n",
      "----------\n",
      "LR 1.0000000000000004e-08\n",
      "train: bce: 0.054596, dice: 0.997972, loss: 0.526284\n",
      "val: bce: 0.056009, dice: 0.997958, loss: 0.526984\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 115/299\n",
      "----------\n",
      "LR 1.0000000000000004e-08\n",
      "train: bce: 0.054594, dice: 0.997972, loss: 0.526283\n",
      "val: bce: 0.056007, dice: 0.997958, loss: 0.526983\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 116/299\n",
      "----------\n",
      "LR 1.0000000000000004e-08\n",
      "train: bce: 0.054591, dice: 0.997973, loss: 0.526282\n",
      "val: bce: 0.056005, dice: 0.997958, loss: 0.526982\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 117/299\n",
      "----------\n",
      "LR 1.0000000000000004e-08\n",
      "train: bce: 0.054589, dice: 0.997973, loss: 0.526281\n",
      "val: bce: 0.056003, dice: 0.997958, loss: 0.526981\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 118/299\n",
      "----------\n",
      "LR 1.0000000000000004e-08\n",
      "train: bce: 0.054587, dice: 0.997973, loss: 0.526280\n",
      "val: bce: 0.056001, dice: 0.997959, loss: 0.526980\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 119/299\n",
      "----------\n",
      "LR 1.0000000000000005e-09\n",
      "train: bce: 0.054585, dice: 0.997973, loss: 0.526279\n",
      "val: bce: 0.056001, dice: 0.997959, loss: 0.526980\n",
      "0m 1s\n",
      "Epoch 120/299\n",
      "----------\n",
      "LR 1.0000000000000005e-09\n",
      "train: bce: 0.054585, dice: 0.997973, loss: 0.526279\n",
      "val: bce: 0.056001, dice: 0.997959, loss: 0.526980\n",
      "0m 1s\n",
      "Epoch 121/299\n",
      "----------\n",
      "LR 1.0000000000000005e-09\n",
      "train: bce: 0.054585, dice: 0.997973, loss: 0.526279\n",
      "val: bce: 0.056001, dice: 0.997959, loss: 0.526980\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 122/299\n",
      "----------\n",
      "LR 1.0000000000000005e-09\n",
      "train: bce: 0.054585, dice: 0.997973, loss: 0.526279\n",
      "val: bce: 0.056001, dice: 0.997959, loss: 0.526980\n",
      "0m 1s\n",
      "Epoch 123/299\n",
      "----------\n",
      "LR 1.0000000000000005e-09\n",
      "train: bce: 0.054585, dice: 0.997973, loss: 0.526279\n",
      "val: bce: 0.056001, dice: 0.997959, loss: 0.526980\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 124/299\n",
      "----------\n",
      "LR 1.0000000000000005e-09\n",
      "train: bce: 0.054585, dice: 0.997973, loss: 0.526279\n",
      "val: bce: 0.056001, dice: 0.997959, loss: 0.526980\n",
      "0m 1s\n",
      "Epoch 125/299\n",
      "----------\n",
      "LR 1.0000000000000005e-09\n",
      "train: bce: 0.054585, dice: 0.997973, loss: 0.526279\n",
      "val: bce: 0.056000, dice: 0.997959, loss: 0.526980\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 126/299\n",
      "----------\n",
      "LR 1.0000000000000005e-09\n",
      "train: bce: 0.054585, dice: 0.997973, loss: 0.526279\n",
      "val: bce: 0.056000, dice: 0.997959, loss: 0.526980\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 127/299\n",
      "----------\n",
      "LR 1.0000000000000005e-09\n",
      "train: bce: 0.054585, dice: 0.997973, loss: 0.526279\n",
      "val: bce: 0.056000, dice: 0.997959, loss: 0.526980\n",
      "0m 1s\n",
      "Epoch 128/299\n",
      "----------\n",
      "LR 1.0000000000000005e-09\n",
      "train: bce: 0.054584, dice: 0.997973, loss: 0.526279\n",
      "val: bce: 0.056000, dice: 0.997959, loss: 0.526979\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 129/299\n",
      "----------\n",
      "LR 1.0000000000000005e-09\n",
      "train: bce: 0.054584, dice: 0.997973, loss: 0.526279\n",
      "val: bce: 0.056000, dice: 0.997959, loss: 0.526979\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 130/299\n",
      "----------\n",
      "LR 1.0000000000000005e-09\n",
      "train: bce: 0.054584, dice: 0.997973, loss: 0.526279\n",
      "val: bce: 0.056000, dice: 0.997959, loss: 0.526979\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 131/299\n",
      "----------\n",
      "LR 1.0000000000000005e-09\n",
      "train: bce: 0.054584, dice: 0.997973, loss: 0.526279\n",
      "val: bce: 0.056000, dice: 0.997959, loss: 0.526979\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 132/299\n",
      "----------\n",
      "LR 1.0000000000000005e-09\n",
      "train: bce: 0.054584, dice: 0.997973, loss: 0.526279\n",
      "val: bce: 0.056000, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 133/299\n",
      "----------\n",
      "LR 1.0000000000000005e-09\n",
      "train: bce: 0.054584, dice: 0.997973, loss: 0.526279\n",
      "val: bce: 0.056000, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 134/299\n",
      "----------\n",
      "LR 1.0000000000000005e-09\n",
      "train: bce: 0.054584, dice: 0.997973, loss: 0.526279\n",
      "val: bce: 0.056000, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 135/299\n",
      "----------\n",
      "LR 1.0000000000000005e-09\n",
      "train: bce: 0.054584, dice: 0.997973, loss: 0.526279\n",
      "val: bce: 0.056000, dice: 0.997959, loss: 0.526979\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 136/299\n",
      "----------\n",
      "LR 1.0000000000000005e-09\n",
      "train: bce: 0.054584, dice: 0.997973, loss: 0.526279\n",
      "val: bce: 0.055999, dice: 0.997959, loss: 0.526979\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 137/299\n",
      "----------\n",
      "LR 1.0000000000000005e-09\n",
      "train: bce: 0.054584, dice: 0.997973, loss: 0.526278\n",
      "val: bce: 0.055999, dice: 0.997959, loss: 0.526979\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 138/299\n",
      "----------\n",
      "LR 1.0000000000000005e-09\n",
      "train: bce: 0.054583, dice: 0.997973, loss: 0.526278\n",
      "val: bce: 0.055999, dice: 0.997959, loss: 0.526979\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 139/299\n",
      "----------\n",
      "LR 1.0000000000000005e-09\n",
      "train: bce: 0.054583, dice: 0.997973, loss: 0.526278\n",
      "val: bce: 0.055999, dice: 0.997959, loss: 0.526979\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 140/299\n",
      "----------\n",
      "LR 1.0000000000000005e-09\n",
      "train: bce: 0.054583, dice: 0.997973, loss: 0.526278\n",
      "val: bce: 0.055999, dice: 0.997959, loss: 0.526979\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 141/299\n",
      "----------\n",
      "LR 1.0000000000000005e-09\n",
      "train: bce: 0.054583, dice: 0.997973, loss: 0.526278\n",
      "val: bce: 0.055999, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 142/299\n",
      "----------\n",
      "LR 1.0000000000000005e-09\n",
      "train: bce: 0.054583, dice: 0.997973, loss: 0.526278\n",
      "val: bce: 0.055999, dice: 0.997959, loss: 0.526979\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 143/299\n",
      "----------\n",
      "LR 1.0000000000000005e-09\n",
      "train: bce: 0.054583, dice: 0.997973, loss: 0.526278\n",
      "val: bce: 0.055999, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 144/299\n",
      "----------\n",
      "LR 1.0000000000000005e-09\n",
      "train: bce: 0.054583, dice: 0.997973, loss: 0.526278\n",
      "val: bce: 0.055999, dice: 0.997959, loss: 0.526979\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 145/299\n",
      "----------\n",
      "LR 1.0000000000000005e-09\n",
      "train: bce: 0.054583, dice: 0.997973, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 146/299\n",
      "----------\n",
      "LR 1.0000000000000005e-09\n",
      "train: bce: 0.054583, dice: 0.997973, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 147/299\n",
      "----------\n",
      "LR 1.0000000000000005e-09\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 148/299\n",
      "----------\n",
      "LR 1.0000000000000005e-09\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "saving best model\n",
      "0m 1s\n",
      "Epoch 149/299\n",
      "----------\n",
      "LR 1.0000000000000006e-10\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 150/299\n",
      "----------\n",
      "LR 1.0000000000000006e-10\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 151/299\n",
      "----------\n",
      "LR 1.0000000000000006e-10\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 152/299\n",
      "----------\n",
      "LR 1.0000000000000006e-10\n",
      "train: bce: 0.054582, dice: 0.997973, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 153/299\n",
      "----------\n",
      "LR 1.0000000000000006e-10\n",
      "train: bce: 0.054582, dice: 0.997973, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 154/299\n",
      "----------\n",
      "LR 1.0000000000000006e-10\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 155/299\n",
      "----------\n",
      "LR 1.0000000000000006e-10\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 156/299\n",
      "----------\n",
      "LR 1.0000000000000006e-10\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 157/299\n",
      "----------\n",
      "LR 1.0000000000000006e-10\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 158/299\n",
      "----------\n",
      "LR 1.0000000000000006e-10\n",
      "train: bce: 0.054582, dice: 0.997973, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 159/299\n",
      "----------\n",
      "LR 1.0000000000000006e-10\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 160/299\n",
      "----------\n",
      "LR 1.0000000000000006e-10\n",
      "train: bce: 0.054582, dice: 0.997973, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 161/299\n",
      "----------\n",
      "LR 1.0000000000000006e-10\n",
      "train: bce: 0.054582, dice: 0.997973, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 162/299\n",
      "----------\n",
      "LR 1.0000000000000006e-10\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 163/299\n",
      "----------\n",
      "LR 1.0000000000000006e-10\n",
      "train: bce: 0.054582, dice: 0.997973, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 164/299\n",
      "----------\n",
      "LR 1.0000000000000006e-10\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 165/299\n",
      "----------\n",
      "LR 1.0000000000000006e-10\n",
      "train: bce: 0.054582, dice: 0.997973, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 166/299\n",
      "----------\n",
      "LR 1.0000000000000006e-10\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 167/299\n",
      "----------\n",
      "LR 1.0000000000000006e-10\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 168/299\n",
      "----------\n",
      "LR 1.0000000000000006e-10\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 169/299\n",
      "----------\n",
      "LR 1.0000000000000006e-10\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 170/299\n",
      "----------\n",
      "LR 1.0000000000000006e-10\n",
      "train: bce: 0.054582, dice: 0.997973, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 171/299\n",
      "----------\n",
      "LR 1.0000000000000006e-10\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 172/299\n",
      "----------\n",
      "LR 1.0000000000000006e-10\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 173/299\n",
      "----------\n",
      "LR 1.0000000000000006e-10\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 174/299\n",
      "----------\n",
      "LR 1.0000000000000006e-10\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 175/299\n",
      "----------\n",
      "LR 1.0000000000000006e-10\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 176/299\n",
      "----------\n",
      "LR 1.0000000000000006e-10\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 177/299\n",
      "----------\n",
      "LR 1.0000000000000006e-10\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 178/299\n",
      "----------\n",
      "LR 1.0000000000000006e-10\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 179/299\n",
      "----------\n",
      "LR 1.0000000000000006e-11\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 180/299\n",
      "----------\n",
      "LR 1.0000000000000006e-11\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 181/299\n",
      "----------\n",
      "LR 1.0000000000000006e-11\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 182/299\n",
      "----------\n",
      "LR 1.0000000000000006e-11\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 183/299\n",
      "----------\n",
      "LR 1.0000000000000006e-11\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 184/299\n",
      "----------\n",
      "LR 1.0000000000000006e-11\n",
      "train: bce: 0.054582, dice: 0.997973, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 185/299\n",
      "----------\n",
      "LR 1.0000000000000006e-11\n",
      "train: bce: 0.054582, dice: 0.997973, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 186/299\n",
      "----------\n",
      "LR 1.0000000000000006e-11\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 187/299\n",
      "----------\n",
      "LR 1.0000000000000006e-11\n",
      "train: bce: 0.054582, dice: 0.997973, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 188/299\n",
      "----------\n",
      "LR 1.0000000000000006e-11\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 189/299\n",
      "----------\n",
      "LR 1.0000000000000006e-11\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 190/299\n",
      "----------\n",
      "LR 1.0000000000000006e-11\n",
      "train: bce: 0.054582, dice: 0.997973, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 191/299\n",
      "----------\n",
      "LR 1.0000000000000006e-11\n",
      "train: bce: 0.054582, dice: 0.997973, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 192/299\n",
      "----------\n",
      "LR 1.0000000000000006e-11\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 193/299\n",
      "----------\n",
      "LR 1.0000000000000006e-11\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 194/299\n",
      "----------\n",
      "LR 1.0000000000000006e-11\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 195/299\n",
      "----------\n",
      "LR 1.0000000000000006e-11\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 196/299\n",
      "----------\n",
      "LR 1.0000000000000006e-11\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 197/299\n",
      "----------\n",
      "LR 1.0000000000000006e-11\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 198/299\n",
      "----------\n",
      "LR 1.0000000000000006e-11\n",
      "train: bce: 0.054582, dice: 0.997973, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 199/299\n",
      "----------\n",
      "LR 1.0000000000000006e-11\n",
      "train: bce: 0.054582, dice: 0.997973, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 200/299\n",
      "----------\n",
      "LR 1.0000000000000006e-11\n",
      "train: bce: 0.054582, dice: 0.997973, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 201/299\n",
      "----------\n",
      "LR 1.0000000000000006e-11\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 202/299\n",
      "----------\n",
      "LR 1.0000000000000006e-11\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 203/299\n",
      "----------\n",
      "LR 1.0000000000000006e-11\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 204/299\n",
      "----------\n",
      "LR 1.0000000000000006e-11\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 205/299\n",
      "----------\n",
      "LR 1.0000000000000006e-11\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 206/299\n",
      "----------\n",
      "LR 1.0000000000000006e-11\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 207/299\n",
      "----------\n",
      "LR 1.0000000000000006e-11\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 208/299\n",
      "----------\n",
      "LR 1.0000000000000006e-11\n",
      "train: bce: 0.054582, dice: 0.997973, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 209/299\n",
      "----------\n",
      "LR 1.0000000000000006e-12\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 210/299\n",
      "----------\n",
      "LR 1.0000000000000006e-12\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 211/299\n",
      "----------\n",
      "LR 1.0000000000000006e-12\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 212/299\n",
      "----------\n",
      "LR 1.0000000000000006e-12\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 213/299\n",
      "----------\n",
      "LR 1.0000000000000006e-12\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 214/299\n",
      "----------\n",
      "LR 1.0000000000000006e-12\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 215/299\n",
      "----------\n",
      "LR 1.0000000000000006e-12\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 216/299\n",
      "----------\n",
      "LR 1.0000000000000006e-12\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 217/299\n",
      "----------\n",
      "LR 1.0000000000000006e-12\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 218/299\n",
      "----------\n",
      "LR 1.0000000000000006e-12\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 219/299\n",
      "----------\n",
      "LR 1.0000000000000006e-12\n",
      "train: bce: 0.054582, dice: 0.997973, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 220/299\n",
      "----------\n",
      "LR 1.0000000000000006e-12\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 221/299\n",
      "----------\n",
      "LR 1.0000000000000006e-12\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 222/299\n",
      "----------\n",
      "LR 1.0000000000000006e-12\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 223/299\n",
      "----------\n",
      "LR 1.0000000000000006e-12\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 224/299\n",
      "----------\n",
      "LR 1.0000000000000006e-12\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 225/299\n",
      "----------\n",
      "LR 1.0000000000000006e-12\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 226/299\n",
      "----------\n",
      "LR 1.0000000000000006e-12\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 227/299\n",
      "----------\n",
      "LR 1.0000000000000006e-12\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 228/299\n",
      "----------\n",
      "LR 1.0000000000000006e-12\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 229/299\n",
      "----------\n",
      "LR 1.0000000000000006e-12\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 230/299\n",
      "----------\n",
      "LR 1.0000000000000006e-12\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 231/299\n",
      "----------\n",
      "LR 1.0000000000000006e-12\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 232/299\n",
      "----------\n",
      "LR 1.0000000000000006e-12\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 233/299\n",
      "----------\n",
      "LR 1.0000000000000006e-12\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 234/299\n",
      "----------\n",
      "LR 1.0000000000000006e-12\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 235/299\n",
      "----------\n",
      "LR 1.0000000000000006e-12\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 236/299\n",
      "----------\n",
      "LR 1.0000000000000006e-12\n",
      "train: bce: 0.054582, dice: 0.997973, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 237/299\n",
      "----------\n",
      "LR 1.0000000000000006e-12\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 238/299\n",
      "----------\n",
      "LR 1.0000000000000006e-12\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 239/299\n",
      "----------\n",
      "LR 1.0000000000000007e-13\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 240/299\n",
      "----------\n",
      "LR 1.0000000000000007e-13\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 241/299\n",
      "----------\n",
      "LR 1.0000000000000007e-13\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 242/299\n",
      "----------\n",
      "LR 1.0000000000000007e-13\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 243/299\n",
      "----------\n",
      "LR 1.0000000000000007e-13\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 244/299\n",
      "----------\n",
      "LR 1.0000000000000007e-13\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 245/299\n",
      "----------\n",
      "LR 1.0000000000000007e-13\n",
      "train: bce: 0.054582, dice: 0.997973, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 246/299\n",
      "----------\n",
      "LR 1.0000000000000007e-13\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 247/299\n",
      "----------\n",
      "LR 1.0000000000000007e-13\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 248/299\n",
      "----------\n",
      "LR 1.0000000000000007e-13\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 249/299\n",
      "----------\n",
      "LR 1.0000000000000007e-13\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 250/299\n",
      "----------\n",
      "LR 1.0000000000000007e-13\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 251/299\n",
      "----------\n",
      "LR 1.0000000000000007e-13\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 252/299\n",
      "----------\n",
      "LR 1.0000000000000007e-13\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 253/299\n",
      "----------\n",
      "LR 1.0000000000000007e-13\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 254/299\n",
      "----------\n",
      "LR 1.0000000000000007e-13\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 255/299\n",
      "----------\n",
      "LR 1.0000000000000007e-13\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 256/299\n",
      "----------\n",
      "LR 1.0000000000000007e-13\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 257/299\n",
      "----------\n",
      "LR 1.0000000000000007e-13\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 258/299\n",
      "----------\n",
      "LR 1.0000000000000007e-13\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 259/299\n",
      "----------\n",
      "LR 1.0000000000000007e-13\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 260/299\n",
      "----------\n",
      "LR 1.0000000000000007e-13\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 261/299\n",
      "----------\n",
      "LR 1.0000000000000007e-13\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 262/299\n",
      "----------\n",
      "LR 1.0000000000000007e-13\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 263/299\n",
      "----------\n",
      "LR 1.0000000000000007e-13\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 264/299\n",
      "----------\n",
      "LR 1.0000000000000007e-13\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 265/299\n",
      "----------\n",
      "LR 1.0000000000000007e-13\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 266/299\n",
      "----------\n",
      "LR 1.0000000000000007e-13\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 267/299\n",
      "----------\n",
      "LR 1.0000000000000007e-13\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 268/299\n",
      "----------\n",
      "LR 1.0000000000000007e-13\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 269/299\n",
      "----------\n",
      "LR 1.0000000000000008e-14\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 270/299\n",
      "----------\n",
      "LR 1.0000000000000008e-14\n",
      "train: bce: 0.054582, dice: 0.997973, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 271/299\n",
      "----------\n",
      "LR 1.0000000000000008e-14\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 272/299\n",
      "----------\n",
      "LR 1.0000000000000008e-14\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 273/299\n",
      "----------\n",
      "LR 1.0000000000000008e-14\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 274/299\n",
      "----------\n",
      "LR 1.0000000000000008e-14\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 275/299\n",
      "----------\n",
      "LR 1.0000000000000008e-14\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 276/299\n",
      "----------\n",
      "LR 1.0000000000000008e-14\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 277/299\n",
      "----------\n",
      "LR 1.0000000000000008e-14\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 278/299\n",
      "----------\n",
      "LR 1.0000000000000008e-14\n",
      "train: bce: 0.054582, dice: 0.997973, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 279/299\n",
      "----------\n",
      "LR 1.0000000000000008e-14\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 280/299\n",
      "----------\n",
      "LR 1.0000000000000008e-14\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 281/299\n",
      "----------\n",
      "LR 1.0000000000000008e-14\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 282/299\n",
      "----------\n",
      "LR 1.0000000000000008e-14\n",
      "train: bce: 0.054582, dice: 0.997973, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 283/299\n",
      "----------\n",
      "LR 1.0000000000000008e-14\n",
      "train: bce: 0.054582, dice: 0.997973, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 284/299\n",
      "----------\n",
      "LR 1.0000000000000008e-14\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 285/299\n",
      "----------\n",
      "LR 1.0000000000000008e-14\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 286/299\n",
      "----------\n",
      "LR 1.0000000000000008e-14\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 287/299\n",
      "----------\n",
      "LR 1.0000000000000008e-14\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 288/299\n",
      "----------\n",
      "LR 1.0000000000000008e-14\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 289/299\n",
      "----------\n",
      "LR 1.0000000000000008e-14\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 290/299\n",
      "----------\n",
      "LR 1.0000000000000008e-14\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 291/299\n",
      "----------\n",
      "LR 1.0000000000000008e-14\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 292/299\n",
      "----------\n",
      "LR 1.0000000000000008e-14\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 293/299\n",
      "----------\n",
      "LR 1.0000000000000008e-14\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 294/299\n",
      "----------\n",
      "LR 1.0000000000000008e-14\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 295/299\n",
      "----------\n",
      "LR 1.0000000000000008e-14\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 296/299\n",
      "----------\n",
      "LR 1.0000000000000008e-14\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 297/299\n",
      "----------\n",
      "LR 1.0000000000000008e-14\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 298/299\n",
      "----------\n",
      "LR 1.0000000000000008e-14\n",
      "train: bce: 0.054582, dice: 0.997973, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Epoch 299/299\n",
      "----------\n",
      "LR 1.0000000000000009e-15\n",
      "train: bce: 0.054582, dice: 0.997974, loss: 0.526278\n",
      "val: bce: 0.055998, dice: 0.997959, loss: 0.526979\n",
      "0m 1s\n",
      "Best val loss: 0.526979\n",
      "(3, 6, 192, 192)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x1200 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_u_net.run(UNet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dice Loss\n",
    "---\n",
    "The Dice coefficient, or Dice-Srensen coefficient, is a common metric for pixel segmentation that can also be modified to act as a loss function:\n",
    "\n",
    "![](https://wikimedia.org/api/rest_v1/media/math/render/svg/a80a97215e1afc0b222e604af1b2099dc9363d3b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PyTorch\n",
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(DiceLoss, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, targets, smooth=1):\n",
    "        \n",
    "        #comment out if your model contains a sigmoid or equivalent activation layer\n",
    "        inputs = F.sigmoid(inputs)       \n",
    "        \n",
    "        #flatten label and prediction tensors\n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "        \n",
    "        intersection = (inputs * targets).sum()                            \n",
    "        dice = (2.*intersection + smooth)/(inputs.sum() + targets.sum() + smooth)  \n",
    "        \n",
    "        return 1 - dice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BCE-Dice Loss\n",
    "---\n",
    "This loss combines Dice loss with the standard binary cross-entropy (BCE) loss that is generally the default for segmentation models. Combining the two methods allows for some diversity in the loss, while benefitting from the stability of BCE. The equation for multi-class BCE by itself will be familiar to anyone who has studied logistic regression:\n",
    "\n",
    "![](https://wikimedia.org/api/rest_v1/media/math/render/svg/80f87a71d3a616a0939f5360cec24d702d2593a2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PyTorch\n",
    "class DiceBCELoss(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(DiceBCELoss, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, targets, smooth=1):\n",
    "        \n",
    "        #comment out if your model contains a sigmoid or equivalent activation layer\n",
    "        inputs = F.sigmoid(inputs)       \n",
    "        \n",
    "        #flatten label and prediction tensors\n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "        \n",
    "        intersection = (inputs * targets).sum()                            \n",
    "        dice_loss = 1 - (2.*intersection + smooth)/(inputs.sum() + targets.sum() + smooth)  \n",
    "        BCE = F.binary_cross_entropy(inputs, targets, reduction='mean')\n",
    "        Dice_BCE = BCE + dice_loss\n",
    "        \n",
    "        return Dice_BCE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "game_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_sample(image, mask, title=\"\"):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    if image.ndim == 3:  # Check if the mask is one-hot encoded\n",
    "        image = np.argmax(image, axis=-1)  # Convert one-hot encoded mask to single-channel\n",
    "\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.title('Image')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    if mask.ndim == 3:  # Check if the mask is one-hot encoded\n",
    "        mask = np.argmax(mask, axis=-1)  # Convert one-hot encoded mask to single-channel\n",
    "    plt.imshow(mask, cmap='gray')  # Using 'jet' to provide distinct colors to different classes\n",
    "    plt.title('Mask')\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.suptitle(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from skimage.io import imshow\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage.transform import resize\n",
    "from skimage.io import imread\n",
    "import os\n",
    "\n",
    "def color_map(N=256, normalized=True):\n",
    "    def bitget(byteval, idx):\n",
    "        return ((byteval & (1 << idx)) != 0)\n",
    "\n",
    "    dtype = 'float32' if normalized else 'uint8'\n",
    "    cmap = np.zeros((N, 3), dtype=dtype)\n",
    "    for i in range(N):\n",
    "        r = g = b = 0\n",
    "        c = i\n",
    "        for j in range(8):\n",
    "            r = r | (bitget(c, 0) << 7-j)\n",
    "            g = g | (bitget(c, 1) << 7-j)\n",
    "            b = b | (bitget(c, 2) << 7-j)\n",
    "            c = c >> 3\n",
    "\n",
    "        cmap[i] = np.array([r, g, b])\n",
    "\n",
    "    cmap = cmap/255 if normalized else cmap\n",
    "    return cmap\n",
    "\n",
    "\n",
    "def color_map_viz():\n",
    "    labels = ['background', 'aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor', 'void']\n",
    "    nclasses = 21\n",
    "    row_size = 50\n",
    "    col_size = 500\n",
    "    cmap = color_map()\n",
    "    array = np.empty((row_size*(nclasses+1), col_size, cmap.shape[1]), dtype=cmap.dtype)\n",
    "    for i in range(nclasses):\n",
    "        array[i*row_size:i*row_size+row_size, :] = cmap[i]\n",
    "    array[nclasses*row_size:nclasses*row_size+row_size, :] = cmap[-1]\n",
    "    \n",
    "    imshow(array)\n",
    "    plt.yticks([row_size*i+row_size/2 for i in range(nclasses+1)], labels)\n",
    "    plt.xticks([])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def color_map_label(normalized=True):\n",
    "    labels = ['background', 'aeroplane', 'bicycle', 'bird', 'boat', 'bottle', 'bus', 'car', 'cat', 'chair', 'cow', 'diningtable', 'dog', 'horse', 'motorbike', 'person', 'pottedplant', 'sheep', 'sofa', 'train', 'tvmonitor', 'void']\n",
    "    nclasses = 21\n",
    "    cmap = color_map()\n",
    "    label_colors = np.empty((nclasses + 1, 3), dtype=cmap.dtype)  # +1 for the 'void' label\n",
    "\n",
    "    for i in range(nclasses + 1):\n",
    "        label_colors[i] = cmap[i] if i < nclasses else cmap[-1]\n",
    "\n",
    "    return label_colors\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2573/2295290231.py:19: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  image = imageio.imread(image_path)\n",
      "/tmp/ipykernel_2573/2295290231.py:20: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  mask_image = imageio.imread(mask_path)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "import os\n",
    "import imageio\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "\n",
    "def preprocess_and_save(image_path, mask_path, cmap, output_size=(224, 224), output_dir='output', log = False):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    # Load and resize image\n",
    "    # image = imread(image_path)\n",
    "\n",
    "    # # Load and resize mask\n",
    "    # mask_image = imread(mask_path)\n",
    "    \n",
    "    image = imageio.imread(image_path)\n",
    "    mask_image = imageio.imread(mask_path)\n",
    "    if log:\n",
    "        plot_sample(image, mask_image, title=f\"{image_path}\")\n",
    "\n",
    "    mask_image = resize(mask_image, output_size, anti_aliasing=False, preserve_range=True).astype(int)\n",
    "    image = resize(image, output_size, anti_aliasing=True) / 255.0  # Normalize to [0, 1]\n",
    "\n",
    "\n",
    "    # Map color to channel index\n",
    "    color_to_index = {tuple(val): idx for idx, val in enumerate(cmap)}\n",
    "\n",
    "    # Initialize 22-channel binary mask\n",
    "    channels = np.zeros((*output_size, 22), dtype=np.float32)\n",
    "\n",
    "    # Vectorized mask processing\n",
    "    # for idx, val in enumerate(cmap):\n",
    "    #     channels[:, :, idx] = np.all(mask_image == val, axis=-1)\n",
    "\n",
    "    channels = np.zeros((*output_size, 22), dtype=np.float32)  # Assuming 22 classes including background\n",
    "    for idx, color in enumerate(cmap):\n",
    "        mask = np.all(mask_image == np.array(color*256, dtype=int), axis=-1).astype(int)\n",
    "        if log:\n",
    "            print(mask)    \n",
    "        channels[:, :, idx] = mask\n",
    "    if log:\n",
    "        plot_sample(image, channels, title=f\"Sample\")\n",
    "        # Use this in your preprocessing function to log unique colors of some masks\n",
    "        # print(\"Unique colors in mask:\", unique_colors(mask_image))\n",
    "\n",
    "    # Save image and mask to binary files\n",
    "    image_filename = os.path.join(output_dir, os.path.basename(image_path) + '_image.npy')\n",
    "    mask_filename = os.path.join(output_dir, os.path.basename(mask_path) + '_mask.npy')\n",
    "    np.save(image_filename, image)\n",
    "    np.save(mask_filename, channels)\n",
    "\n",
    "def process_dataset(image_dir, mask_dir, cmap):\n",
    "    file_names = os.listdir(image_dir)\n",
    "    tasks = []\n",
    "    count = 1\n",
    "    log = False\n",
    "    with ThreadPoolExecutor(max_workers=4) as executor:\n",
    "        for file_name in file_names:\n",
    "            count+=1\n",
    "            if count > 10:\n",
    "                log = False\n",
    "            if file_name.endswith('.jpg'):\n",
    "                mask_name = file_name[:-4] + '.png'  # Change extension for mask\n",
    "                mask_path = os.path.join(mask_dir, mask_name)\n",
    "                image_path = os.path.join(image_dir, file_name)\n",
    "\n",
    "                if os.path.exists(mask_path):\n",
    "                    tasks.append(executor.submit(preprocess_and_save, image_path, mask_path, cmap, (224, 224), 'output', log))\n",
    "\n",
    "    # Optional: wait for all tasks to complete and handle exceptions\n",
    "    for task in tasks:\n",
    "        task.result()  # This will raise any exceptions caught during the thread execution\n",
    "\n",
    "# Assume color_map function is defined and provides the cmap array\n",
    "cmap = color_map_label()  # Assuming this function returns the correct RGB values for each class\n",
    "\n",
    "image_dir = '../data/VOC2007/JPEGImages'\n",
    "mask_dir = '../data/VOC2007/SegmentationClass'\n",
    "process_dataset(image_dir, mask_dir, cmap)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(337, 224, 224, 3)\n",
      "(337, 224, 224, 22)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-03 17:48:52.600326: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 1488019456 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-03 17:48:54.926054: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Dropout, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "# gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "# if gpus:\n",
    "#     try:\n",
    "#         # Currently, memory growth needs to be the same across GPUs\n",
    "#         for gpu in gpus:\n",
    "#             tf.config.experimental.set_memory_growth(gpu, True)\n",
    "#         logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "#         print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "#     except RuntimeError as e:\n",
    "#         # Memory growth must be set before GPUs have been initialized\n",
    "#         print(e)\n",
    "\n",
    "\n",
    "def load_data(directory):\n",
    "    images = []\n",
    "    masks = []\n",
    "    for filename in sorted(os.listdir(directory)):\n",
    "        if filename.endswith('_image.npy'):\n",
    "            images.append(np.load(os.path.join(directory, filename)))\n",
    "        elif filename.endswith('_mask.npy'):\n",
    "            masks.append(np.load(os.path.join(directory, filename)))\n",
    "    return np.array(images), np.array(masks)\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_data(images, masks, train_size=0.8, test_size=0.1, random_state=42):\n",
    "    # Split into train and remaining (test + validation)\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "        images, masks, train_size=train_size, random_state=random_state, shuffle=True)\n",
    "\n",
    "    # Split the remaining into test and validation\n",
    "    X_val, X_test, y_val, y_test = train_test_split(\n",
    "        X_temp, y_temp, test_size=0.5, random_state=random_state, shuffle=True)\n",
    "    \n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test\n",
    "\n",
    "output_dir = 'output'\n",
    "images, masks = load_data(output_dir)\n",
    "\n",
    "\n",
    "# print(images.shape)\n",
    "\n",
    "# train_imgs, test_imgs, train_masks, test_masks = train_test_split(images, masks, test_size=0.2, random_state=42)\n",
    "# train_imgs, val_imgs, train_masks, val_masks = train_test_split(train_imgs, train_masks, test_size=0.125, random_state=42)  # 0.125 x 0.8 = 0.1\n",
    "\n",
    "# print(train_imgs.shape)\n",
    "# print(train_masks.shape)\n",
    "\n",
    "# Split the data\n",
    "train_imgs, val_imgs, test_imgs, train_masks, val_masks, test_masks = split_data(images, masks)\n",
    "print(train_imgs.shape)\n",
    "print(train_masks.shape)\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "import keras.backend as K\n",
    "\n",
    "#Keras\n",
    "def DiceBCELoss(targets, inputs, smooth=1e-6):    \n",
    "       \n",
    "    #flatten label and prediction tensors\n",
    "    inputs = K.flatten(inputs)\n",
    "    targets = K.flatten(targets)\n",
    "    \n",
    "    BCE =  binary_crossentropy(targets, inputs)\n",
    "    intersection = K.sum(K.dot(targets, inputs))    \n",
    "    dice_loss = 1 - (2*intersection + smooth) / (K.sum(targets) + K.sum(inputs) + smooth)\n",
    "    Dice_BCE = BCE + dice_loss\n",
    "    \n",
    "    return Dice_BCE\n",
    "\n",
    "def dice_coefficient(y_true, y_pred, smooth=1e-6):\n",
    "    y_true_f = tf.keras.backend.flatten(y_true)\n",
    "    y_pred_f = tf.keras.backend.flatten(y_pred)\n",
    "    intersection = tf.keras.backend.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) + smooth)\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    return 1 - dice_coefficient(y_true, y_pred)\n",
    "\n",
    "\n",
    "def conv_block(input_tensor, num_filters):\n",
    "    \"\"\"A block of two convolutional layers with ReLU activations and batch normalization.\"\"\"\n",
    "    x = Conv2D(num_filters, (3, 3), activation='relu', padding='same')(input_tensor)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(num_filters, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    return x\n",
    "\n",
    "def encoder_block(input_tensor, num_filters):\n",
    "    \"\"\"An encoder block with a convolution block followed by max pooling.\"\"\"\n",
    "    x = conv_block(input_tensor, num_filters)\n",
    "    p = MaxPooling2D((2, 2))(x)\n",
    "    return x, p\n",
    "\n",
    "def decoder_block(input_tensor, concat_tensor, num_filters):\n",
    "    \"\"\"A decoder block with upsampling, concatenation, and a convolution block.\"\"\"\n",
    "    x = UpSampling2D((2, 2))(input_tensor)\n",
    "    x = concatenate([x, concat_tensor])\n",
    "    x = conv_block(x, num_filters)\n",
    "    return x\n",
    "\n",
    "def unet_model(input_size=(224, 224, 3), num_classes=22):\n",
    "    inputs = Input(input_size)\n",
    "\n",
    "    # Encoder\n",
    "    c1, p1 = encoder_block(inputs, 64)\n",
    "    c2, p2 = encoder_block(p1, 128)\n",
    "    c3, p3 = encoder_block(p2, 256)\n",
    "    c4, p4 = encoder_block(p3, 512)\n",
    "    \n",
    "    # Bridge\n",
    "    b = conv_block(p4, 1024)\n",
    "\n",
    "    # Decoder\n",
    "    d1 = decoder_block(b, c4, 512)\n",
    "    d2 = decoder_block(d1, c3, 256)\n",
    "    d3 = decoder_block(d2, c2, 128)\n",
    "    d4 = decoder_block(d3, c1, 64)\n",
    "\n",
    "    # Output\n",
    "    outputs = Conv2D(num_classes, (1, 1), activation='softmax')(d4)\n",
    "\n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "    model.compile(optimizer=Adam(lr=1e-5), loss=dice_loss, metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "# Create the U-Net model\n",
    "model = unet_model()\n",
    "# model.summary()\n",
    "\n",
    "# Training the model\n",
    "history = model.fit(train_imgs, train_masks, validation_data=(val_imgs, val_masks), batch_size=1, epochs=100)\n",
    "\n",
    "# Plot training and validation Dice loss\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.plot(history.history['accuracy'], label='Accuracy')\n",
    "plt.title('Training and Validation Dice Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# tf.keras.backend.clear_session()\n",
    "\n",
    "# # Define Dice loss function and coefficient\n",
    "# def dice_coefficient(y_true, y_pred, smooth=1e-6):\n",
    "#     y_true_f = tf.keras.backend.flatten(y_true)\n",
    "#     y_pred_f = tf.keras.backend.flatten(y_pred)\n",
    "#     intersection = tf.keras.backend.sum(y_true_f * y_pred_f)\n",
    "#     return (2. * intersection + smooth) / (tf.keras.backend.sum(y_true_f) + tf.keras.backend.sum(y_pred_f) + smooth)\n",
    "\n",
    "# def dice_loss(y_true, y_pred):\n",
    "#     return 1 - dice_coefficient(y_true, y_pred)\n",
    "\n",
    "# def unet_model(input_size=(224, 224, 3), num_classes=22):\n",
    "#     inputs = Input(input_size)\n",
    "    \n",
    "#     # Downward path\n",
    "#     c1 = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "#     c1 = Dropout(0.1)(c1)\n",
    "#     c1 = Conv2D(32, (3, 3), activation='relu', padding='same')(c1)\n",
    "#     p1 = MaxPooling2D((2, 2))(c1)\n",
    "    \n",
    "#     c2 = Conv2D(64, (3, 3), activation='relu', padding='same')(p1)\n",
    "#     c2 = Dropout(0.1)(c2)\n",
    "#     c2 = Conv2D(64, (3, 3), activation='relu', padding='same')(c2)\n",
    "#     p2 = MaxPooling2D((2, 2))(c2)\n",
    "\n",
    "#     # Bottleneck\n",
    "#     c3 = Conv2D(128, (3, 3), activation='relu', padding='same')(p2)\n",
    "#     c3 = Dropout(0.2)(c3)\n",
    "#     c3 = Conv2D(128, (3, 3), activation='relu', padding='same')(c3)\n",
    "\n",
    "#     # Upward path\n",
    "#     u4 = UpSampling2D((2, 2))(c3)\n",
    "#     u4 = concatenate([u4, c2])\n",
    "#     c4 = Conv2D(64, (3, 3), activation='relu', padding='same')(u4)\n",
    "#     c4 = Dropout(0.1)(c4)\n",
    "#     c4 = Conv2D(64, (3, 3), activation='relu', padding='same')(c4)\n",
    "    \n",
    "#     u5 = UpSampling2D((2, 2))(c4)\n",
    "#     u5 = concatenate([u5, c1])\n",
    "#     c5 = Conv2D(32, (3, 3), activation='relu', padding='same')(u5)\n",
    "#     c5 = Dropout(0.1)(c5)\n",
    "#     c5 = Conv2D(32, (3, 3), activation='relu', padding='same')(c5)\n",
    "    \n",
    "#     outputs = Conv2D(num_classes, (1, 1), activation='sigmoid')(c5)\n",
    "\n",
    "#     model = Model(inputs=[inputs], outputs=[outputs])\n",
    "#     model.compile(optimizer=Adam(learning_rate=1e-5), loss=dice_loss, metrics=[dice_coefficient])\n",
    "\n",
    "#     return model\n",
    "\n",
    "# # Initialize the U-Net model\n",
    "# model = unet_model()\n",
    "# # model.summary()  # This will print the summary of the model without needing Graphviz\n",
    "\n",
    "# # Assume data preparation here (X_train, Y_train, X_val, Y_val)\n",
    "\n",
    "# # Training the model\n",
    "# history = model.fit(train_imgs, train_masks, validation_data=(val_imgs, val_masks), batch_size=16, epochs=20)\n",
    "\n",
    "# # Plot training and validation Dice loss\n",
    "# plt.figure(figsize=(8, 5))\n",
    "# plt.plot(history.history['loss'], label='Training Loss')\n",
    "# plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "# plt.title('Training and Validation Dice Loss')\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.legend()\n",
    "# plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rai_py38_poetry_enn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
